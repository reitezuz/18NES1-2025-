{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reitezuz/18NES1-2025-/blob/main/week7/multiclass_classification_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfX7M9hjkWsC"
      },
      "source": [
        "# Multiclass classification example - classifying digits from the MNIST dataset\n",
        "\n",
        "Inspired by: https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter02_mathematical-building-blocks.ipynb  \n",
        "\n",
        "MNIST dataset is a dataset of handwritten digits. It contains a training set of 60000 greyscale 28x28 images and a testing set of 10000 images of digits written by different people.\n",
        "\n",
        "https://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "https://en.wikipedia.org/wiki/MNIST_database\n",
        "\n",
        "\n",
        "For further reference datasets for deep learning, investigate:\n",
        "https://keras.io/api/datasets/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzwRu2_8ViC7"
      },
      "source": [
        "## Load, observe and analyze the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwVsc3VekVh7"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST dataset\n",
        "import keras\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hrCLc9IViC_"
      },
      "source": [
        "Observe the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvvntzS9lg7M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 60000 training samples - images 28x28 in greyscale\n",
        "print(train_images.shape, train_labels.shape)\n",
        "\n",
        "# 10000 testing samples - images 28x28 in greyscale\n",
        "print(test_images.shape, test_labels.shape)\n",
        "\n",
        "# 10 categories\n",
        "print(len(train_labels), train_labels[:10], np.min(train_labels), np.max(train_labels))\n",
        "\n",
        "print(\"Extremes of pixel values:\", np.min(train_images), np.max(train_images))\n",
        "\n",
        "# Distribution of training and testing labels\n",
        "print(\"Label distribution:\", np.bincount(train_labels))\n",
        "print(\"Label distribution:\", np.bincount(test_labels))\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Number of missing values in training images:\", np.sum(np.isnan(train_images)))\n",
        "print(\"Number of missing values in test images:\", np.sum(np.isnan(test_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHr6LuBMomDO"
      },
      "outputs": [],
      "source": [
        "# Display some images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the first 10 images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])  # Remove axis ticks and the grids\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary) # Display the current image using a binary color map\n",
        "    plt.xlabel(train_labels[i])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YaqVCUJViDB"
      },
      "source": [
        "**Observation:**\n",
        "1. The letters are well centered and similar in size, no values ​​are missing, there are no missing values -> we need no data augmentation\n",
        "2. The input data have the form of 3D-tensor.\n",
        "3. The pixels have values 0...255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHxfENUMrEQi"
      },
      "source": [
        "## Preprocess the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwVnJ6fdrDgr"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "# 1. Reshape and normalize the data:\n",
        "# reshape the data into a flat vector (784 elements) for input to our MLP neural network.\n",
        "x_train_0 = train_images.reshape(60000, 28 * 28)\n",
        "x_test_0 = test_images.reshape(10000, 28 * 28)\n",
        "y_train = train_labels\n",
        "y_test = test_labels\n",
        "\n",
        "# 2. Convert the pixel values from integers [0-255] to floating-point numbers and normalize them to the range [0, 1].\n",
        "x_train = x_train_0.astype('float32') / 255\n",
        "x_test = x_test_0.astype('float32') / 255\n",
        "\n",
        "# 3. Arbitrary: one-hot encode the labels:\n",
        "# For example, the label 3 would become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].\n",
        "y_train_categorical = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test_categorical  = keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# print(x_train[1])\n",
        "print(y_train[:3])\n",
        "print(y_train_categorical[:3])\n",
        "\n",
        "# 4. Split the training data into training and validation sets\n",
        "# The validation set is used to monitor the performance of the model during training and prevent overfitting.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiItbng2zUM3"
      },
      "source": [
        "## Define and train the model\n",
        "\n",
        "### MLP model for multiclass classification:\n",
        "- 'softmax' activation function in the output layer\n",
        "- 'relu' or 'tanh' in the hidden layers\n",
        "- if labels are one-hot vectors:\n",
        "    CategoricalCrossentropy  loss function and CategoricalAccuracy metrics\n",
        "\n",
        "- if labels are provided as integers:\n",
        "     SparseCategoricalCrossentropy  loss function and SparseCategoricalAccuracy metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiS5smsrViDJ"
      },
      "outputs": [],
      "source": [
        "# Data frame for results\n",
        "import pandas as pd\n",
        "\n",
        "columns = [\"Model Name\", \"Test Accuracy\", \"Test Loss\", \"Train Accuracy\", \"Train Loss\", \"Time (s)\", \"Epochs\", \"Details\"]\n",
        "results_df = pd.DataFrame(columns=columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training progress:\n",
        "def plot_history(history):\n",
        "    history_dict = history.history\n",
        "    print(history_dict.keys())\n",
        "\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Yispa2xCfm-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGV8yvJgzSU3"
      },
      "outputs": [],
      "source": [
        "# Set some of the hyperparameters:\n",
        "do_early_stopping = True\n",
        "max_epochs = 10\n",
        "batch_size = 128\n",
        "num_neur_1 = 512 # number of neurons in the first hidden layer\n",
        "# num_neur_2 = 50 # number of neurons in the second hidden layer\n",
        "hidden_activation = 'relu'\n",
        "do_tensorboard = True\n",
        "\n",
        "###############################################\n",
        "# Define the model architecture\n",
        "from keras import layers\n",
        "model = keras.Sequential([\n",
        "    layers.InputLayer(shape=(28 * 28,)),    # Input layer\n",
        "    #layers.Dense(num_neur_1, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros') # First hidden layer\n",
        "    layers.Dense(num_neur_1, activation=hidden_activation),\n",
        "    # layers.Dense(num_neur_2, activation=hidden_activation),\n",
        "    layers.Dense(10, activation='softmax')  # Output layer for multiclass classification\n",
        "])\n",
        "import datetime\n",
        "model_name = \"mnist_mlp_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.keras'\n",
        "model.summary()\n",
        "\n",
        "# Configure the model:\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate = 0.001), # Adam, RMSProp\n",
        "              loss= keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics= [keras.metrics.SparseCategoricalAccuracy(\"accuracy\")])\n",
        "\n",
        "###############################################\n",
        "# Define callbacks (e.g., early stopping):\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "callbacks = [early_stopping] if do_early_stopping else []\n",
        "if do_tensorboard:\n",
        "    from keras.callbacks import TensorBoard\n",
        "    tensorboard_callback = TensorBoard(log_dir=\"./logs_mnist/\"+model_name, histogram_freq=1, write_steps_per_second=True)\n",
        "    callbacks.append(tensorboard_callback)\n",
        "\n",
        "################################################\n",
        "# Train the model\n",
        "import time\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=max_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=[tensorboard_callback])\n",
        "time_fit = time.time() - start_time\n",
        "\n",
        "###############################\n",
        "# Plot the training progress:\n",
        "plot_history(history)\n",
        "\n",
        "# Evaluate the model on the training, validation and test sets\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "val_loss, val_acc = model.evaluate(x_val, y_val)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Training accuracy:', train_acc, '\\nTrain loss:', train_loss)\n",
        "print('Validation accuracy:', val_acc, '\\nVal loss:', val_loss)\n",
        "print('Test accuracy:', test_acc, '\\nTest loss:', test_loss)\n",
        "\n",
        "###############################\n",
        "# Save the model:\n",
        "import os\n",
        "model_dir = \"./models/\"\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "model.save(model_dir + model_name)\n",
        "\n",
        "#################################\n",
        "# Add results to the dataframe:\n",
        "model_details = f\"{num_neur_1}-{hidden_activation}-{do_early_stopping}-ep.:{max_epochs}-bs:{batch_size}\"\n",
        "new_entry = {\n",
        "    \"Model Name\" : model_name,\n",
        "    \"Details\" : model_details,\n",
        "    \"Test Accuracy\" : test_acc,\n",
        "    \"Test Loss\" : test_loss,\n",
        "    \"Train Accuracy\" : train_acc,\n",
        "    \"Train Loss\" : train_loss,\n",
        "    \"Time (s)\" : time_fit,\n",
        "    \"Epochs\" : len(history.epoch),\n",
        "}\n",
        "# View and and save the dataframe:\n",
        "results_df.to_csv(model_dir + \"mnist_results.csv\", index=False)\n",
        "print(\"Results:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU8cUnQS-oVY"
      },
      "outputs": [],
      "source": [
        "# plot the training progress:\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_dict['accuracy'])\n",
        "plt.plot(history_dict['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history_dict['loss'])\n",
        "plt.plot(history_dict['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9oYaO_138aa"
      },
      "source": [
        "## Evaluate the model and make predictions on new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNHkFYxs_K9T"
      },
      "outputs": [],
      "source": [
        "# Get predicted probabilities for the test set\n",
        "y_pred_probs = model.predict(x_test)\n",
        "print(y_pred_probs[0])\n",
        "\n",
        "# Get the predicted class for each sample\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"Predicted labels:\", y_pred[:10])\n",
        "print(\"True labels:\", y_test[:10])\n",
        "\n",
        "# Misclassified indices:\n",
        "misclassified_indices = np.where(y_pred != y_test)[0]\n",
        "num_misclassified = len(misclassified_indices)\n",
        "print(\"Number of misclassified images:\", num_misclassified,\n",
        "      \"out of\", len(y_test), \", accuracy\", test_acc)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot some misclassified images\n",
        "num_images_to_plot = 5\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(min(num_images_to_plot, len(misclassified_indices))):\n",
        "    index = misclassified_indices[i]\n",
        "    plt.subplot(1, num_images_to_plot, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[index], cmap=plt.cm.binary)\n",
        "    plt.xlabel(f\"Pred: {y_pred[index]}, True: {y_test[index]}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6XQlpZb__0M"
      },
      "outputs": [],
      "source": [
        "# Plot some misclassified images from a given target (or predicted) class\n",
        "target_class = 3\n",
        "misclassified_indices_class = np.where((y_pred != y_test) & (y_test == target_class))[0]\n",
        "#misclassified_indices_class = np.where((y_pred != y_test) & (y_pred == target_class))[0]\n",
        "\n",
        "\n",
        "\n",
        "# Display the first 25 misclassified images for the target class\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(min(25, len(misclassified_indices_class))):\n",
        "    index = misclassified_indices_class[i]\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[index], cmap=plt.cm.binary)\n",
        "    plt.xlabel(f\"True:{y_test[index]}, Pred:{y_pred[index]}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eAc9Q0WViDP"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# Load TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Start TensorBoard before training begins\n",
        "%tensorboard --logdir logs/fit_mnist --reload_interval=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn-GJqLSQ-dO"
      },
      "source": [
        "# Exercises\n",
        "1. **Change the number of layers and neurons in the model**. Observe how this affects the model's accuracy. You can also experiment with different **activation functions** in the hidden layers.\n",
        "2. **Experiment with the number of epochs and learning rate**. Plot the learning curves to visualize the differences in training.\n",
        "3. **Change the loss function**. Try using `categorical_crossentropy` with one-hot encoded labels (`y`).\n",
        "4. **Experiment with different batch sizes**. Observe how different batch sizes affect the model's accuracy and training time.\n",
        "5. **Try an alternative normalization method for the input data** (e.g., standardization). Observe how this affects the model's performance.\n",
        "6. **Analyze the confusion matrix**. Use the confusion matrix to identify pairs of classes that are most frequently misclassified.\n",
        "7. **Try changing the optimizer used in the model**. Experiment with optimizers such as Adam, RMSprop, or Adagrad to see how they impact model accuracy and training time.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}